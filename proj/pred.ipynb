{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e22ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = pd.read_csv(\"consultations.csv\", encoding=\"utf-8-sig\", parse_dates=[\"start_time\",\"end_time\",\"consultation_date\"])\n",
    "cft  = pd.read_csv(\"consultation_fund_types.csv\", encoding=\"utf-8-sig\")\n",
    "ft   = pd.read_csv(\"fund_types.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa61d7",
   "metadata": {},
   "source": [
    "1) 공통 전처리: 슬롯/요일 생성 + sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a66fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 존재하는 시간대: [9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "요일 분포(0=월 ~ 6=일):\n",
      " weekday\n",
      "0    5925\n",
      "1    5954\n",
      "2    6047\n",
      "3    6064\n",
      "4    6010\n",
      "Name: count, dtype: int64\n",
      "slot_hour   9    10   11   12    13    14    15   16   17\n",
      "weekday                                                  \n",
      "0          387  365  409  394  1227  1221  1169  391  362\n",
      "1          398  456  378  368  1174  1193  1194  429  364\n",
      "2          380  366  426  399  1216  1200  1247  377  436\n",
      "3          397  416  379  427  1172  1219  1238  402  414\n",
      "4          381  420  379  385  1209  1207  1239  413  377\n"
     ]
    }
   ],
   "source": [
    "# --- 슬롯/요일 컬럼 만들기 ---\n",
    "base = cons.copy()\n",
    "base[\"ts_slot\"]   = base[\"start_time\"].dt.floor(\"h\")   # 09:23 -> 09:00\n",
    "base[\"slot_hour\"] = base[\"ts_slot\"].dt.hour            # 9,10,11,...\n",
    "base[\"weekday\"]   = base[\"ts_slot\"].dt.weekday         # 0=월 ~ 6=일\n",
    "\n",
    "# --- 확인(이미 9–18, 점심 제외) ---\n",
    "allowed_hours = sorted(base[\"slot_hour\"].unique().tolist())\n",
    "print(\"데이터에 존재하는 시간대:\", allowed_hours)\n",
    "print(\"요일 분포(0=월 ~ 6=일):\\n\", base[\"weekday\"].value_counts().sort_index())\n",
    "print(pd.crosstab(base[\"weekday\"], base[\"slot_hour\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e9d056",
   "metadata": {},
   "source": [
    "2) 회귀용 프레임 만들기 (슬롯별 상담 건수 y)\n",
    "- 핵심: 날짜×시간 그리드를 만들고 상담이 없던 슬롯도 y=0으로 채움 -> 학습 안정화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca36a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[회귀용 Xy_reg 미리보기]\n",
      "        date  slot_hour             ts_slot  weekday     y      hour_sin  \\\n",
      "0 2025-01-02          9 2025-01-02 09:00:00        3  11.0  7.071068e-01   \n",
      "1 2025-01-02         10 2025-01-02 10:00:00        3  11.0  5.000000e-01   \n",
      "2 2025-01-02         11 2025-01-02 11:00:00        3  17.0  2.588190e-01   \n",
      "3 2025-01-02         12 2025-01-02 12:00:00        3  14.0  1.224647e-16   \n",
      "4 2025-01-02         13 2025-01-02 13:00:00        3  33.0 -2.588190e-01   \n",
      "\n",
      "   hour_cos  lag_1  lag_day   roll_day  \n",
      "0 -0.707107    5.0      8.0  13.444444  \n",
      "1 -0.866025   11.0     11.0  13.444444  \n",
      "2 -0.965926   11.0      6.0  14.666667  \n",
      "3 -1.000000   17.0     11.0  15.000000  \n",
      "4 -0.965926   14.0     17.0  16.777778  \n",
      "['date', 'slot_hour', 'ts_slot', 'weekday', 'y', 'hour_sin', 'hour_cos', 'lag_1', 'lag_day', 'roll_day']\n"
     ]
    }
   ],
   "source": [
    "# --- 날짜 × (데이터에 실제 존재하는) 시간대 그리드 ---\n",
    "days = pd.date_range(base[\"ts_slot\"].dt.normalize().min(),\n",
    "                     base[\"ts_slot\"].dt.normalize().max(), freq=\"D\")\n",
    "\n",
    "grid = (pd.DataFrame({\"date\": days}).assign(key=1)\n",
    "        .merge(pd.DataFrame({\"slot_hour\": allowed_hours, \"key\":1}), on=\"key\")\n",
    "        .drop(\"key\", axis=1))\n",
    "grid[\"ts_slot\"] = grid[\"date\"] + pd.to_timedelta(grid[\"slot_hour\"], unit=\"h\")\n",
    "grid[\"weekday\"] = grid[\"ts_slot\"].dt.weekday\n",
    "\n",
    "# --- y = 슬롯별 상담 건수 (없으면 0으로 채움) ---\n",
    "y_cnt = base.groupby(\"ts_slot\").size().rename(\"y\").reset_index()\n",
    "Xy_reg = (grid.merge(y_cnt, on=\"ts_slot\", how=\"left\")\n",
    "               .fillna({\"y\":0})\n",
    "               .sort_values(\"ts_slot\").reset_index(drop=True))\n",
    "\n",
    "# --- 간단 파생 피처 ---\n",
    "Xy_reg[\"hour_sin\"] = np.sin(2*np.pi*Xy_reg[\"slot_hour\"]/24)\n",
    "Xy_reg[\"hour_cos\"] = np.cos(2*np.pi*Xy_reg[\"slot_hour\"]/24)\n",
    "\n",
    "# 직전 슬롯(lag_1)\n",
    "Xy_reg[\"lag_1\"] = Xy_reg[\"y\"].shift(1)\n",
    "\n",
    "# 전일 같은 슬롯(lag_day): ts_slot을 +1일 시켜서 맞춰붙이기 (슬롯 수가 24가 아니어도 안전)\n",
    "prev = Xy_reg[[\"ts_slot\",\"y\"]].copy()\n",
    "prev[\"ts_slot\"] = prev[\"ts_slot\"] + pd.Timedelta(days=1)\n",
    "Xy_reg = Xy_reg.merge(prev.rename(columns={\"y\":\"lag_day\"}), on=\"ts_slot\", how=\"left\")\n",
    "\n",
    "# 하루 이동평균 (운영 슬롯 수 기준)\n",
    "slots_per_day = len(allowed_hours)\n",
    "Xy_reg[\"roll_day\"] = Xy_reg[\"y\"].rolling(slots_per_day, min_periods=1).mean()\n",
    "\n",
    "# 래깅으로 생긴 앞부분 결측 제거\n",
    "Xy_reg = Xy_reg.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"\\n[회귀용 Xy_reg 미리보기]\")\n",
    "print(Xy_reg.head())\n",
    "print(Xy_reg.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad37aeb",
   "metadata": {},
   "source": [
    "3) 분류용 프레임 만들기 (슬롯별 최다 자금유형 label)\n",
    "\n",
    "- 핵심: 슬롯×자금유형 건수를 세고 각 슬롯에서 가장 많은 유형을 라벨로 잡아줌\n",
    "- 보조 피처: 지난주 같은 슬롯의 라벨(label_lag7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53cc5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[대분류 기준 분류용 Xy_cls 미리보기]\n",
      "              ts_slot  label  cnt  weekday  slot_hour label_lag7  wd_0  wd_1  \\\n",
      "0 2025-01-01 09:00:00    일반형    6        2          9      OTHER     0     0   \n",
      "1 2025-01-01 10:00:00     창업    6        2         10      OTHER     0     0   \n",
      "2 2025-01-01 11:00:00  스마트공장    3        2         11      OTHER     0     0   \n",
      "3 2025-01-01 12:00:00    일반형    6        2         12      OTHER     0     0   \n",
      "4 2025-01-01 13:00:00     창업    8        2         13      OTHER     0     0   \n",
      "\n",
      "   wd_2  wd_3  wd_4  lag7_OTHER  lag7_스마트공장  lag7_스마트기술  lag7_운전자금  lag7_일반형  \\\n",
      "0     1     0     0           1           0           0          0         0   \n",
      "1     1     0     0           1           0           0          0         0   \n",
      "2     1     0     0           1           0           0          0         0   \n",
      "3     1     0     0           1           0           0          0         0   \n",
      "4     1     0     0           1           0           0          0         0   \n",
      "\n",
      "   lag7_창업  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "['ts_slot', 'label', 'cnt', 'weekday', 'slot_hour', 'label_lag7', 'wd_0', 'wd_1', 'wd_2', 'wd_3', 'wd_4', 'lag7_OTHER', 'lag7_스마트공장', 'lag7_스마트기술', 'lag7_운전자금', 'lag7_일반형', 'lag7_창업']\n"
     ]
    }
   ],
   "source": [
    "# ========= 대분류 라벨 파이프라인 =========\n",
    "import re\n",
    "\n",
    "# 1) fund_type_name -> major(대분류) 변환기\n",
    "def to_major(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"OTHER\"\n",
    "    s = str(name).strip()\n",
    "    # 하이픈 다양성 처리: -, –(en dash), —(em dash)\n",
    "    parts = re.split(r\"\\s*[-–—]\\s*\", s, maxsplit=1)\n",
    "    major = parts[0].strip()\n",
    "    return major if major else s  # 비어있으면 원본\n",
    "\n",
    "# 2) 이벤트 단위로 ts_slot/weekday/slot_hour 붙이고 'major' 생성\n",
    "cf = (\n",
    "    cft.merge(base[[\"consultation_id\",\"ts_slot\",\"weekday\",\"slot_hour\"]],\n",
    "              on=\"consultation_id\", how=\"inner\")\n",
    "      .merge(ft, on=\"fund_type_id\", how=\"left\")\n",
    ")\n",
    "cf[\"major\"] = cf[\"fund_type_name\"].map(to_major)\n",
    "\n",
    "# 3) 슬롯 × 대분류 건수 집계\n",
    "slot_cnt_major = (\n",
    "    cf.groupby([\"ts_slot\",\"major\"]).size()\n",
    "      .rename(\"cnt\").reset_index()\n",
    ")\n",
    "\n",
    "# 4) 같은 ts_slot 내에서 cnt 최댓값 대분류 하나 선택(동률 시 처음 것)\n",
    "top_major = (\n",
    "    slot_cnt_major.sort_values([\"ts_slot\",\"cnt\"], ascending=[True, False])\n",
    "                  .drop_duplicates(\"ts_slot\")\n",
    "                  .rename(columns={\"major\":\"label\"})\n",
    "                  .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 5) 피처 붙이기: 요일/슬롯시각\n",
    "Xy_cls = (\n",
    "    top_major.merge(\n",
    "        base.drop_duplicates(\"ts_slot\")[[\"ts_slot\",\"weekday\",\"slot_hour\"]],\n",
    "        on=\"ts_slot\", how=\"left\"\n",
    "    )\n",
    "    .sort_values(\"ts_slot\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 6) 지난주 같은 슬롯의 '대분류' 라벨(lag7) 붙이기\n",
    "lag = Xy_cls[[\"ts_slot\",\"label\"]].copy()\n",
    "lag[\"ts_slot\"] = lag[\"ts_slot\"] + pd.Timedelta(days=7)\n",
    "Xy_cls = Xy_cls.merge(lag.rename(columns={\"label\":\"label_lag7\"}), on=\"ts_slot\", how=\"left\")\n",
    "Xy_cls[\"label_lag7\"] = Xy_cls[\"label_lag7\"].fillna(\"OTHER\")\n",
    "\n",
    "# 7) 원핫 인코딩(요일, 지난주 대분류)\n",
    "Xy_cls = pd.concat([\n",
    "    Xy_cls,\n",
    "    pd.get_dummies(Xy_cls[\"weekday\"],    prefix=\"wd\",   drop_first=False),\n",
    "    pd.get_dummies(Xy_cls[\"label_lag7\"], prefix=\"lag7\", drop_first=False)\n",
    "], axis=1)\n",
    "\n",
    "# (옵션) 불리언을 0/1로 바꾸고 싶다면:\n",
    "bool_cols = Xy_cls.select_dtypes(include=[\"bool\"]).columns\n",
    "Xy_cls[bool_cols] = Xy_cls[bool_cols].astype(\"uint8\")\n",
    "\n",
    "print(\"\\n[대분류 기준 분류용 Xy_cls 미리보기]\")\n",
    "print(Xy_cls.head())\n",
    "print(Xy_cls.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d484d4",
   "metadata": {},
   "source": [
    "## 1) 회귀 — 슬롯(1시간)별 상담 건수 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96f93019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\hi_ml_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\hi_ml_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[회귀] 결과 요약\n",
      "Baseline(day-ago) RMSE = 13.251\n",
      "RF => {'RMSE': 3.805}\n",
      "HGB_P => {'RMSE': 4.144}\n",
      "XGB_MSE => {'RMSE': 3.7, 'BestIter': 158}\n",
      "XGB_Pois => {'RMSE': 3.684, 'BestIter': 359}\n",
      "ENS(0.75*XGB_Pois+0.25*RF) => {'RMSE': 3.668}\n",
      "=> 최종 Best: ENS(0.75*XGB_Pois+0.25*RF) (RMSE=3.668)\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 회귀: 시간 슬롯별 y(건수) 예측\n",
    "# =======================\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def take(A, idx):\n",
    "    return A.iloc[idx] if hasattr(A, \"iloc\") else A[idx]\n",
    "\n",
    "# ---- (A) 피처/타깃 준비 ----\n",
    "feature_cols = [\"weekday\",\"slot_hour\",\"hour_sin\",\"hour_cos\",\"lag_1\",\"lag_day\",\"roll_day\"]\n",
    "X = Xy_reg[feature_cols].astype(float)\n",
    "y = Xy_reg[\"y\"].astype(float)\n",
    "t = Xy_reg[\"ts_slot\"]\n",
    "\n",
    "# ---- (B) 시간순 split: Train 80% 중 뒤쪽 10%를 Valid, 마지막 20% Test ----\n",
    "n = len(X)\n",
    "idx = np.arange(n)\n",
    "cut_test = int(n * 0.8)\n",
    "tr_all_idx, te_idx = idx[:cut_test], idx[cut_test:]\n",
    "cut_val = int(len(tr_all_idx) * 0.9)\n",
    "tr_idx, val_idx = tr_all_idx[:cut_val], tr_all_idx[cut_val:]\n",
    "\n",
    "X_tr_all, y_tr_all = take(X, tr_all_idx), take(y, tr_all_idx)\n",
    "X_te,      y_te    = take(X, te_idx),     take(y, te_idx)\n",
    "X_tr, y_tr         = take(X, tr_idx),     take(y, tr_idx)\n",
    "X_val, y_val       = take(X, val_idx),    take(y, val_idx)\n",
    "t_te               = take(t, te_idx)\n",
    "\n",
    "# ---- (C) 나이브 베이스라인(전일 같은 슬롯값) ----\n",
    "# lag_day가 드물게 비면 0으로 보정(앞에서 dropna 했으면 거의 없음)\n",
    "base_pred = Xy_reg.loc[te_idx, \"lag_day\"].to_numpy()\n",
    "base_pred = np.where(np.isnan(base_pred), 0.0, base_pred)\n",
    "rmse_base = rmse(y_te, base_pred)\n",
    "\n",
    "# ---- (D) 모델들 정의 ----\n",
    "# RF: 조금 더 깊게, 잎 최소 샘플 완화 → 패턴 포착력↑ + 과적합 억제\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=900, max_depth=6, min_samples_leaf=6,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# HGB Poisson: 카운트 데이터 특성 활용 (y >= 0 가정)\n",
    "hgb_p = HistGradientBoostingRegressor(\n",
    "    loss=\"poisson\", learning_rate=0.07,\n",
    "    max_iter=800, max_leaf_nodes=31,\n",
    "    min_samples_leaf=20, random_state=42\n",
    ")\n",
    "\n",
    "# XGB (평균제곱오차)\n",
    "xgb_mse = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=2000,  # early stopping으로 최적 스텝 선택\n",
    "    learning_rate=0.05, max_depth=6, min_child_weight=2,\n",
    "    subsample=0.9, colsample_bytree=0.9,\n",
    "    reg_lambda=1.0, reg_alpha=0.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# XGB (포아송/카운트) - 과도한 과소/과대 추정 완화용 대안\n",
    "xgb_pois = XGBRegressor(\n",
    "    objective=\"count:poisson\",\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05, max_depth=6, min_child_weight=2,\n",
    "    subsample=0.9, colsample_bytree=0.9,\n",
    "    max_delta_step=1.0,  # 포아송 안정화\n",
    "    reg_lambda=1.0, reg_alpha=0.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "metrics = {\"Baseline(day-ago)\": {\"RMSE\": rmse_base}}\n",
    "preds_reg = pd.DataFrame({\"ts_slot\": t_te.values, \"y_true\": y_te.values})\n",
    "\n",
    "# ---- (E) 학습/예측 ----\n",
    "# RF/HGB는 tr_all 전체로 적합해서 test에 예측\n",
    "rf.fit(X_tr_all, y_tr_all)\n",
    "p_rf = rf.predict(X_te)\n",
    "metrics[\"RF\"] = {\"RMSE\": rmse(y_te, p_rf)}\n",
    "preds_reg[\"y_pred_RF\"] = p_rf\n",
    "\n",
    "hgb_p.fit(X_tr_all, y_tr_all)\n",
    "p_hgb = hgb_p.predict(X_te)\n",
    "metrics[\"HGB_P\"] = {\"RMSE\": rmse(y_te, p_hgb)}\n",
    "preds_reg[\"y_pred_HGB_P\"] = p_hgb\n",
    "\n",
    "# XGB는 Train/Valid로 early stopping → 과적합 방지\n",
    "xgb_mse.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "p_xgb_mse = xgb_mse.predict(X_te)\n",
    "metrics[\"XGB_MSE\"] = {\"RMSE\": rmse(y_te, p_xgb_mse), \"BestIter\": int(xgb_mse.best_iteration)}\n",
    "preds_reg[\"y_pred_XGB_MSE\"] = p_xgb_mse\n",
    "\n",
    "xgb_pois.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "p_xgb_pois = xgb_pois.predict(X_te)\n",
    "metrics[\"XGB_Pois\"] = {\"RMSE\": rmse(y_te, p_xgb_pois), \"BestIter\": int(xgb_pois.best_iteration)}\n",
    "preds_reg[\"y_pred_XGB_Pois\"] = p_xgb_pois\n",
    "\n",
    "# ---- (F) 간단 앙상블: XGB(둘 중 더 좋은 것) + RF 가중 평균 ----\n",
    "# 어떤 XGB가 더 좋은지 선택\n",
    "rmse_xgb_mse = metrics[\"XGB_MSE\"][\"RMSE\"]\n",
    "rmse_xgb_poi = metrics[\"XGB_Pois\"][\"RMSE\"]\n",
    "if rmse_xgb_mse <= rmse_xgb_poi:\n",
    "    tag_main = \"XGB_MSE\"\n",
    "    p_main   = p_xgb_mse\n",
    "else:\n",
    "    tag_main = \"XGB_Pois\"\n",
    "    p_main   = p_xgb_pois\n",
    "\n",
    "best_w, best_rmse, best_pred = None, float(\"inf\"), None\n",
    "for w in np.linspace(0.0, 1.0, 21):  # 0.00 ~ 1.00 (0.05 간격)\n",
    "    p_ens = w*p_main + (1-w)*p_rf\n",
    "    r = rmse(y_te, p_ens)\n",
    "    if r < best_rmse:\n",
    "        best_w, best_rmse, best_pred = w, r, p_ens\n",
    "\n",
    "ens_name = f\"ENS({best_w:.2f}*{tag_main}+{1-best_w:.2f}*RF)\"\n",
    "metrics[ens_name] = {\"RMSE\": best_rmse}\n",
    "preds_reg[\"y_pred_ENS\"] = best_pred\n",
    "preds_reg[\"resid_ENS\"]  = preds_reg[\"y_true\"] - preds_reg[\"y_pred_ENS\"]\n",
    "\n",
    "# ---- (G) 결과 요약 출력 ----\n",
    "def fmt(m):\n",
    "    out = {k: (round(v,3) if isinstance(v,float) else v) for k,v in m.items()}\n",
    "    return out\n",
    "print(\"[회귀] 결과 요약\")\n",
    "print(f\"Baseline(day-ago) RMSE = {rmse_base:.3f}\")\n",
    "for k,v in metrics.items():\n",
    "    if k!=\"Baseline(day-ago)\":\n",
    "        print(k, \"=>\", fmt(v))\n",
    "\n",
    "best_model = min([k for k in metrics], key=lambda k: metrics[k][\"RMSE\"])\n",
    "print(f\"=> 최종 Best: {best_model} (RMSE={metrics[best_model]['RMSE']:.3f})\")\n",
    "\n",
    "# (선택) 저장\n",
    "preds_reg.to_csv(\"predictions_test.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(metrics).T.reset_index().rename(columns={\"index\":\"Model\"}).to_csv(\"metrics_test.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe8d8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# --- 내일 날짜 슬롯 만들기 ---\n",
    "last_day = Xy_reg[\"ts_slot\"].dt.normalize().max()\n",
    "tomorrow = last_day + pd.Timedelta(days=1)\n",
    "\n",
    "grid_next = pd.DataFrame({\"slot_hour\": allowed_hours})\n",
    "grid_next[\"date\"] = tomorrow\n",
    "grid_next[\"ts_slot\"] = grid_next[\"date\"] + pd.to_timedelta(grid_next[\"slot_hour\"], unit=\"h\")\n",
    "grid_next[\"weekday\"] = grid_next[\"ts_slot\"].dt.weekday\n",
    "\n",
    "# --- 회귀용 피처 (lag_1, lag_day, roll_day 반영 필요) ---\n",
    "# lag_day는 전일 같은 슬롯 → Xy_reg 마지막날 데이터를 참조\n",
    "prev_ser = (\n",
    "    Xy_reg.loc[Xy_reg[\"ts_slot\"].dt.normalize() == last_day, [\"slot_hour\",\"y\"]]\n",
    "          .drop_duplicates(\"slot_hour\")\n",
    "          .set_index(\"slot_hour\")[\"y\"]   # 여기까지만!\n",
    ")\n",
    "grid_next[\"lag_day\"] = grid_next[\"slot_hour\"].map(prev_ser).fillna(0.0)\n",
    "\n",
    "# sin/cos\n",
    "grid_next[\"hour_sin\"] = np.sin(2*np.pi*grid_next[\"slot_hour\"]/24)\n",
    "grid_next[\"hour_cos\"] = np.cos(2*np.pi*grid_next[\"slot_hour\"]/24)\n",
    "\n",
    "# lag_1: 첫 슬롯은 전일 마지막 슬롯 값 사용\n",
    "y_last = Xy_reg.iloc[-1][\"y\"]\n",
    "grid_next[\"lag_1\"] = [y_last] + [np.nan]*(len(grid_next)-1)\n",
    "\n",
    "# roll_day: 직전 하루 평균\n",
    "roll_last = Xy_reg[Xy_reg[\"ts_slot\"].dt.normalize() == last_day][\"y\"].mean()\n",
    "grid_next[\"roll_day\"] = roll_last\n",
    "\n",
    "# --- 모델 학습 (전체로 다시 fit) ---\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=900, max_depth=6, min_samples_leaf=6,\n",
    "    random_state=42, n_jobs=-1\n",
    ").fit(X, y)\n",
    "\n",
    "xgb_pois_final = XGBRegressor(\n",
    "    objective=\"count:poisson\",\n",
    "    n_estimators=int(xgb_pois.best_iteration),   # early stopping에서 찾은 best_iter\n",
    "    learning_rate=0.05, max_depth=6, min_child_weight=2,\n",
    "    subsample=0.9, colsample_bytree=0.9,\n",
    "    max_delta_step=1.0, reg_lambda=1.0, reg_alpha=0.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ").fit(X, y)\n",
    "\n",
    "# 2) ENS 예측 함수 정의\n",
    "def ens_predict(X_new, w=0.75):\n",
    "    p_xgb = xgb_pois_final.predict(X_new)\n",
    "    p_rf  = rf_final.predict(X_new)\n",
    "    return w*p_xgb + (1-w)*p_rf\n",
    "\n",
    "# 3) 내일 grid_next 같은 데이터에 적용\n",
    "y_pred_next = ens_predict(grid_next[feature_cols], w=0.75)\n",
    "\n",
    "grid_next_reg = grid_next[[\"ts_slot\",\"weekday\",\"slot_hour\"]].copy()\n",
    "grid_next_reg[\"y_pred\"] = y_pred_next\n",
    "grid_next_reg.to_csv(\"predictions_tomorrow.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b498b",
   "metadata": {},
   "source": [
    "## 2) 분류 — 슬롯(1시간)별 최다 자금유형 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afab6925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\hi_ml_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[분류] Baseline(lag7) ACC=0.456\n",
      "RF => {'AUC_macro': 0.7906, 'ACC': 0.5508, 'Top-3': 0.8066}\n",
      "XGB => {'AUC_macro': 0.8443, 'ACC': 0.6295, 'Top-3': 0.9443, 'BestIter': 451}\n",
      "ENS(0.55*XGB+0.45*RF) => {'AUC_macro': 0.8204, 'ACC': 0.6164, 'Top-3': 0.9311}\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 분류: 슬롯별 최다 자금유형 예측\n",
    "# =======================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- (안전) 멀티클래스 AUC 계산 보조 ---\n",
    "def macro_auc_safe(y_true_str, proba, classes_str, clf_classes_str):\n",
    "    idx = {c:i for i,c in enumerate(clf_classes_str)}\n",
    "    aligned = np.zeros((proba.shape[0], len(classes_str)))\n",
    "    for j, c in enumerate(classes_str):\n",
    "        aligned[:, j] = proba[:, idx[c]] if c in idx else 0.0\n",
    "    aucs = []\n",
    "    for j, c in enumerate(classes_str):\n",
    "        y_bin = (y_true_str == c).astype(int)\n",
    "        if y_bin.min() == y_bin.max():\n",
    "            continue\n",
    "        aucs.append(roc_auc_score(y_bin, aligned[:, j]))\n",
    "    return float(np.mean(aucs)) if aucs else float(\"nan\")\n",
    "\n",
    "# ---- (A) 피처/타깃 준비 ----\n",
    "feature_cols_cls = (\n",
    "    [\"slot_hour\"] +\n",
    "    [c for c in Xy_cls.columns if c.startswith(\"wd_\")] +\n",
    "    [c for c in Xy_cls.columns if c.startswith(\"lag7_\")]\n",
    ")\n",
    "\n",
    "# ---- (B) 시간순 split: 마지막 20% Test, Train의 뒤쪽 10% Valid ----\n",
    "n = len(Xy_cls)\n",
    "cut_te = int(n * 0.8)\n",
    "train_all = Xy_cls.iloc[:cut_te].copy()\n",
    "test      = Xy_cls.iloc[cut_te:].copy()\n",
    "\n",
    "# ---- (C) 라벨 축소: train 기준 TopK + OTHER (누수 방지) ----\n",
    "topK = 10\n",
    "headK = train_all[\"label\"].value_counts().nlargest(topK).index\n",
    "train_all[\"y_str\"] = np.where(train_all[\"label\"].isin(headK), train_all[\"label\"], \"OTHER\")\n",
    "test[\"y_str\"]      = np.where(test[\"label\"].isin(headK),      test[\"label\"],      \"OTHER\")\n",
    "\n",
    "# [ADD] lag7 인코더: 누수 방지를 위해 train_all 기준으로 학습\n",
    "# OTHER가 없을 수 있으니 보장\n",
    "_lag_pool = pd.Index(train_all[\"label_lag7\"].fillna(\"OTHER\")).astype(str)\n",
    "if \"OTHER\" not in _lag_pool:\n",
    "    _lag_pool = _lag_pool.append(pd.Index([\"OTHER\"]))\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_lag = LabelEncoder().fit(_lag_pool)\n",
    "\n",
    "# [ADD] lag7_enc 정수 피처 + lag7_same(지난주와 동일 여부) + lag7_headK(지난주가 상위라벨?)\n",
    "train_all[\"lag7_enc\"]  = le_lag.transform(train_all[\"label_lag7\"].fillna(\"OTHER\").astype(str))\n",
    "test[\"lag7_enc\"]       = le_lag.transform(test[\"label_lag7\"].fillna(\"OTHER\").astype(str))\n",
    "train_all[\"lag7_same\"] = (train_all[\"label_lag7\"] == train_all[\"y_str\"]).astype(\"uint8\")\n",
    "test[\"lag7_same\"]      = (test[\"label_lag7\"] == test[\"y_str\"]).astype(\"uint8\")\n",
    "train_all[\"lag7_headK\"] = train_all[\"label_lag7\"].isin(headK).astype(\"uint8\")\n",
    "test[\"lag7_headK\"]      = test[\"label_lag7\"].isin(headK).astype(\"uint8\")\n",
    "\n",
    "# ---- (D) Train→Train/Valid (시간순) ----\n",
    "m = len(train_all)\n",
    "cut_val = int(m * 0.9)\n",
    "train = train_all.iloc[:cut_val].copy()\n",
    "valid = train_all.iloc[cut_val:].copy()\n",
    "\n",
    "# ---- (E) 인코딩 ----\n",
    "le = LabelEncoder().fit(np.unique(np.concatenate([train_all[\"y_str\"].values, test[\"y_str\"].values])))\n",
    "y_tr   = le.transform(train[\"y_str\"].values)\n",
    "y_val  = le.transform(valid[\"y_str\"].values)\n",
    "y_test = le.transform(test[\"y_str\"].values)\n",
    "\n",
    "# [REPLACE] 피처 목록 확장: 기존 one-hot + lag7 강화 피처 3개 추가\n",
    "feature_cols_cls2 = (\n",
    "    [\"slot_hour\"] +\n",
    "    [c for c in Xy_cls.columns if c.startswith(\"wd_\")] +\n",
    "    [c for c in Xy_cls.columns if c.startswith(\"lag7_\")] +  # 기존 one-hot들\n",
    "    [\"lag7_enc\", \"lag7_same\", \"lag7_headK\"]                # [ADD]\n",
    ")\n",
    "\n",
    "X_tr   = train[feature_cols_cls2].astype(float)\n",
    "X_val  = valid[feature_cols_cls2].astype(float)\n",
    "X_te   = test[feature_cols_cls2].astype(float)\n",
    "# ---- (F) 불균형 보정: 샘플가중치 (역빈도) ----\n",
    "freq = pd.Series(y_tr).value_counts(normalize=True)\n",
    "w_map = {cls: 1.0/max(p, 1e-9) for cls, p in freq.items()}\n",
    "w_tr = np.array([w_map[c] for c in y_tr], dtype=float)\n",
    "w_tr = w_tr / w_tr.mean()\n",
    "\n",
    "# ---- (G) 나이브 베이스라인 (지난주 라벨) ----\n",
    "test_lag7 = np.where(test[\"label_lag7\"].isin(le.classes_), test[\"label_lag7\"], \"OTHER\")\n",
    "acc_base  = (test_lag7 == test[\"y_str\"].values).mean()\n",
    "\n",
    "# ---- (H) 모델 정의 ----\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=900, max_depth=8, min_samples_leaf=3,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
    "    n_estimators=3000,          # 충분히 크게 두고 ES로 최적 스텝\n",
    "    learning_rate=0.05, max_depth=4, min_child_weight=2,\n",
    "    subsample=0.85, colsample_bytree=0.85,\n",
    "    reg_lambda=2.0, reg_alpha=1.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "results = {}\n",
    "preds_cls = pd.DataFrame({\"ts_slot\": test[\"ts_slot\"].values})\n",
    "\n",
    "# ---- (I) 학습/예측 (RF) ----\n",
    "rf.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "proba_val_rf = rf.predict_proba(X_val)                  # (n_val, C)\n",
    "proba_te_rf  = rf.predict_proba(X_te)\n",
    "pred_te_rf   = rf.predict(X_te)\n",
    "preds_cls[\"pred_RF\"] = le.inverse_transform(pred_te_rf)\n",
    "# 모델 내부 정수→문자열 클래스 매핑\n",
    "classes_str_model_rf = le.inverse_transform(rf.classes_)\n",
    "# 메트릭\n",
    "acc_rf  = accuracy_score(y_test, pred_te_rf)\n",
    "top3_rf = np.mean([le.inverse_transform([yy])[0] in le.inverse_transform(np.argsort(proba_te_rf[i])[::-1][:3])\n",
    "                   for i, yy in enumerate(y_test)])\n",
    "auc_rf  = macro_auc_safe(le.inverse_transform(y_test),\n",
    "                         proba_te_rf, classes_str=le.classes_,\n",
    "                         clf_classes_str=classes_str_model_rf)\n",
    "\n",
    "results[\"RF\"] = {\"AUC_macro\": float(auc_rf), \"ACC\": float(acc_rf), \"Top-3\": float(top3_rf)}\n",
    "\n",
    "# ---- (J) 학습/예측 (XGB, early stopping: Valid 사용) ----\n",
    "xgb.fit(\n",
    "    X_tr, y_tr,\n",
    "    sample_weight=w_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=False\n",
    ")\n",
    "proba_val_xgb = xgb.predict_proba(X_val)\n",
    "proba_te_xgb  = xgb.predict_proba(X_te)\n",
    "pred_te_xgb   = xgb.predict(X_te)\n",
    "preds_cls[\"pred_XGB\"] = le.inverse_transform(pred_te_xgb)\n",
    "\n",
    "classes_str_model_xgb = le.inverse_transform(xgb.classes_)\n",
    "acc_xgb  = accuracy_score(y_test, pred_te_xgb)\n",
    "top3_xgb = np.mean([le.inverse_transform([yy])[0] in le.inverse_transform(np.argsort(proba_te_xgb[i])[::-1][:3])\n",
    "                    for i, yy in enumerate(y_test)])\n",
    "auc_xgb  = macro_auc_safe(le.inverse_transform(y_test),\n",
    "                          proba_te_xgb, classes_str=le.classes_,\n",
    "                          clf_classes_str=classes_str_model_xgb)\n",
    "\n",
    "results[\"XGB\"] = {\"AUC_macro\": float(auc_xgb), \"ACC\": float(acc_xgb), \"Top-3\": float(top3_xgb), \"BestIter\": int(getattr(xgb, \"best_iteration\", 0))}\n",
    "\n",
    "# ---- (K) 확률 앙상블: w*XGB + (1-w)*RF  (w는 VALID에서 Top-3 최대화로 탐색) ----\n",
    "best_w, best_metric = None, -1.0\n",
    "for w in np.linspace(0.0, 1.0, 21):  # 0.00~1.00\n",
    "    # valid 기준 정렬/클래스정합 필요 없음: 두 모델 모두 le 기준 클래스 순서\n",
    "    proba_val_ens = w*proba_val_xgb + (1-w)*proba_val_rf\n",
    "    # valid Top-3\n",
    "    order = np.argsort(proba_val_ens, axis=1)[:, ::-1]\n",
    "    top3_valid = np.mean([train_all[\"y_str\"].values[cut_val + i] in le.inverse_transform(order[i, :3])\n",
    "                          for i in range(len(order))])\n",
    "    if top3_valid > best_metric:\n",
    "        best_metric, best_w = top3_valid, w\n",
    "\n",
    "# 최적 w로 test 집합 예측/지표\n",
    "proba_te_ens = best_w*proba_te_xgb + (1-best_w)*proba_te_rf\n",
    "pred_te_ens  = np.argmax(proba_te_ens, axis=1)\n",
    "preds_cls[\"pred_ENS\"] = le.inverse_transform(pred_te_ens)\n",
    "\n",
    "# Top-1/Top-3/매크로AUC\n",
    "acc_ens  = accuracy_score(y_test, pred_te_ens)\n",
    "order    = np.argsort(proba_te_ens, axis=1)[:, ::-1]\n",
    "top3_ens = np.mean([le.inverse_transform([yy])[0] in le.inverse_transform(order[i, :3])\n",
    "                    for i, yy in enumerate(y_test)])\n",
    "auc_ens  = macro_auc_safe(le.inverse_transform(y_test),\n",
    "                          proba_te_ens, classes_str=le.classes_,\n",
    "                          clf_classes_str=le.classes_)  # 이미 정렬됨\n",
    "\n",
    "results[f\"ENS({best_w:.2f}*XGB+{1-best_w:.2f}*RF)\"] = {\n",
    "    \"AUC_macro\": float(auc_ens), \"ACC\": float(acc_ens), \"Top-3\": float(top3_ens)\n",
    "}\n",
    "\n",
    "# ---- (L) 대시보드용 Top-3 결과 칼럼 ----\n",
    "labels_str = le.classes_\n",
    "preds_cls[\"p1_ENS\"]   = proba_te_ens[np.arange(len(proba_te_ens)), np.argmax(proba_te_ens, axis=1)].astype(float)\n",
    "\n",
    "order = np.argsort(proba_te_ens, axis=1)[:, ::-1]\n",
    "k = min(3, proba_te_ens.shape[1])\n",
    "top_idx = order[:, :k]\n",
    "preds_cls[\"ens_top1\"] = labels_str[top_idx[:,0]]\n",
    "preds_cls[\"ens_p1\"]   = proba_te_ens[np.arange(len(proba_te_ens)), top_idx[:,0]].astype(float)\n",
    "if k >= 2:\n",
    "    preds_cls[\"ens_top2\"] = labels_str[top_idx[:,1]]\n",
    "    preds_cls[\"ens_p2\"]   = proba_te_ens[np.arange(len(proba_te_ens)), top_idx[:,1]].astype(float)\n",
    "if k >= 3:\n",
    "    preds_cls[\"ens_top3\"] = labels_str[top_idx[:,2]]\n",
    "    preds_cls[\"ens_p3\"]   = proba_te_ens[np.arange(len(proba_te_ens)), top_idx[:,2]].astype(float)\n",
    "\n",
    "# (선택) 요일/시간대 메타\n",
    "if (\"weekday\" not in preds_cls.columns) and (\"weekday\" in test.columns):\n",
    "    preds_cls = preds_cls.join(test[[\"weekday\",\"slot_hour\"]].reset_index(drop=True))\n",
    "weekday_map = {0:\"월\",1:\"화\",2:\"수\",3:\"목\",4:\"금\",5:\"토\",6:\"일\"}\n",
    "if \"weekday\" in preds_cls.columns and \"weekday_ko\" not in preds_cls.columns:\n",
    "    preds_cls[\"weekday_ko\"] = preds_cls[\"weekday\"].map(weekday_map)\n",
    "\n",
    "# ---- (M) 결과 출력 ----\n",
    "def _round(d):\n",
    "    return {k: (round(v,4) if isinstance(v,float) else v) for k,v in d.items()}\n",
    "\n",
    "print(f\"[분류] Baseline(lag7) ACC={acc_base:.3f}\")\n",
    "for k,v in results.items():\n",
    "    print(k, \"=>\", _round(v))\n",
    "\n",
    "# (선택) 저장\n",
    "preds_cls.to_csv(\"cls_predictions_test.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(results).T.reset_index().rename(columns={\"index\":\"Model\"}).to_csv(\"cls_metrics_table.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "893e7a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\hi_ml_env\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 내일 분류 예측 저장: cls_pred_tomorrow_xgb.csv  (XGB, n_estimators=158)\n"
     ]
    }
   ],
   "source": [
    "wd_cols    = [c for c in Xy_cls.columns if c.startswith(\"wd_\")]\n",
    "lag7_cols  = [c for c in Xy_cls.columns if c.startswith(\"lag7_\")]\n",
    "feature_cols_cls2 = [\"slot_hour\"] + wd_cols + lag7_cols + [\"lag7_enc\",\"lag7_same\",\"lag7_headK\"]\n",
    "\n",
    "# 1) 시간순 split\n",
    "n = len(Xy_cls)\n",
    "cut_te = int(n * 0.8)\n",
    "train_all = Xy_cls.iloc[:cut_te].copy()\n",
    "test      = Xy_cls.iloc[cut_te:].copy()\n",
    "\n",
    "# 2) 라벨 축소(누수 방지): train 기준 TopK + OTHER\n",
    "topK  = 10\n",
    "headK = train_all[\"label\"].value_counts().nlargest(topK).index\n",
    "train_all[\"y_str\"] = np.where(train_all[\"label\"].isin(headK), train_all[\"label\"], \"OTHER\")\n",
    "test[\"y_str\"]      = np.where(test[\"label\"].isin(headK),      test[\"label\"],      \"OTHER\")\n",
    "\n",
    "# 3) lag7 인코더(누수 방지: train_all 기준) + 강화피처\n",
    "_lag_pool = pd.Index(train_all[\"label_lag7\"].fillna(\"OTHER\").astype(str))\n",
    "if \"OTHER\" not in _lag_pool:\n",
    "    _lag_pool = _lag_pool.append(pd.Index([\"OTHER\"]))\n",
    "le_lag = LabelEncoder().fit(_lag_pool)\n",
    "\n",
    "train_all[\"lag7_enc\"]   = le_lag.transform(train_all[\"label_lag7\"].fillna(\"OTHER\").astype(str))\n",
    "test[\"lag7_enc\"]        = le_lag.transform(test[\"label_lag7\"].fillna(\"OTHER\").astype(str))\n",
    "train_all[\"lag7_same\"]  = (train_all[\"label_lag7\"] == train_all[\"y_str\"]).astype(\"uint8\")\n",
    "test[\"lag7_same\"]       = (test[\"label_lag7\"] == test[\"y_str\"]).astype(\"uint8\")\n",
    "train_all[\"lag7_headK\"] = train_all[\"label_lag7\"].isin(headK).astype(\"uint8\")\n",
    "test[\"lag7_headK\"]      = test[\"label_lag7\"].isin(headK).astype(\"uint8\")\n",
    "\n",
    "# 4) Train/Valid (시간순 9:1)\n",
    "m = len(train_all)\n",
    "cut_val = int(m * 0.9)\n",
    "train = train_all.iloc[:cut_val].copy()\n",
    "valid = train_all.iloc[cut_val:].copy()\n",
    "\n",
    "# 5) 라벨 인코더(최종 클래스)\n",
    "le = LabelEncoder().fit(\n",
    "    np.unique(np.concatenate([train_all[\"y_str\"].values, test[\"y_str\"].values]))\n",
    ")\n",
    "\n",
    "X_tr   = train[feature_cols_cls2].astype(float)\n",
    "X_val  = valid[feature_cols_cls2].astype(float)\n",
    "X_all  = train_all[feature_cols_cls2].astype(float)      # 최종 재학습용\n",
    "y_tr   = le.transform(train[\"y_str\"].values)\n",
    "y_val  = le.transform(valid[\"y_str\"].values)\n",
    "y_all  = le.transform(train_all[\"y_str\"].values)\n",
    "\n",
    "# 6) XGB 학습(early stopping) → best_iteration 추출\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
    "    n_estimators=3000, learning_rate=0.05, max_depth=4, min_child_weight=2,\n",
    "    subsample=0.85, colsample_bytree=0.85,\n",
    "    reg_lambda=2.0, reg_alpha=1.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "best_iter = int(getattr(xgb, \"best_iteration\", 300))\n",
    "best_iter = max(best_iter, 50)  # 안전판\n",
    "\n",
    "# 7) 최종 재학습(전체 train_all)\n",
    "xgb_final = XGBClassifier(\n",
    "    objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
    "    n_estimators=best_iter, learning_rate=0.05, max_depth=4, min_child_weight=2,\n",
    "    subsample=0.85, colsample_bytree=0.85,\n",
    "    reg_lambda=2.0, reg_alpha=1.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb_final.fit(X_all, y_all)\n",
    "\n",
    "# ===== 내일 그리드 생성 & 피처 구성 (Xy_cls 파이프라인과 동일 전제) =====\n",
    "last_day = Xy_cls[\"ts_slot\"].dt.normalize().max()\n",
    "tomorrow = last_day + pd.Timedelta(days=1)\n",
    "allowed_hours = sorted(Xy_cls[\"slot_hour\"].unique().tolist())\n",
    "\n",
    "grid_next = pd.DataFrame({\"slot_hour\": allowed_hours})\n",
    "grid_next[\"date\"] = tomorrow\n",
    "# grid_next[\"ts_slot\"] = grid_next[\"date\"] + pd.to_datetime(grid_next[\"slot_hour\"], unit=\"h\").dt.to_pytimedelta()\n",
    "# 위 한 줄이 환경에 따라 경고가 나면 아래 대체 사용:\n",
    "grid_next[\"ts_slot\"] = grid_next[\"date\"] + pd.to_timedelta(grid_next[\"slot_hour\"], unit=\"h\")\n",
    "\n",
    "grid_next[\"weekday\"] = grid_next[\"ts_slot\"].dt.weekday\n",
    "\n",
    "# 지난주 같은 슬롯 라벨(lag7): Xy_cls에서 가져오기 (네가 만든 major 기반 label)\n",
    "last_week_day = tomorrow - pd.Timedelta(days=7)\n",
    "lag7_map = (Xy_cls[Xy_cls[\"ts_slot\"].dt.normalize() == last_week_day]\n",
    "            .drop_duplicates(\"slot_hour\")\n",
    "            .set_index(\"slot_hour\")[\"label\"])\n",
    "grid_next[\"label_lag7\"] = grid_next[\"slot_hour\"].map(lag7_map).fillna(\"OTHER\")\n",
    "\n",
    "# one-hot(요일/lag7) – 학습시 존재했던 컬럼 집합과 정확히 맞추기\n",
    "wd_next   = pd.get_dummies(grid_next[\"weekday\"],    prefix=\"wd\",   drop_first=False)\n",
    "lag7_next = pd.get_dummies(grid_next[\"label_lag7\"], prefix=\"lag7\", drop_first=False)\n",
    "\n",
    "wd_next   = wd_next.reindex(columns=wd_cols,   fill_value=0)\n",
    "lag7_next = lag7_next.reindex(columns=lag7_cols, fill_value=0)\n",
    "\n",
    "# 강화 피처(내일은 정답 없음 → same=0, headK는 신호 유지)\n",
    "grid_next[\"lag7_enc\"]   = le_lag.transform(\n",
    "    grid_next[\"label_lag7\"].where(grid_next[\"label_lag7\"].isin(le_lag.classes_), \"OTHER\").astype(str)\n",
    ")\n",
    "grid_next[\"lag7_same\"]  = 0\n",
    "grid_next[\"lag7_headK\"] = grid_next[\"label_lag7\"].isin(headK).astype(\"uint8\")\n",
    "\n",
    "# 예측용 피처 프레임(학습 순서/개수와 100% 동일)\n",
    "X_next_parts = pd.concat([\n",
    "    grid_next[[\"slot_hour\"]].astype(float).reset_index(drop=True),\n",
    "    wd_next.astype(float).reset_index(drop=True),\n",
    "    lag7_next.astype(float).reset_index(drop=True),\n",
    "    grid_next[[\"lag7_enc\",\"lag7_same\",\"lag7_headK\"]].astype(float).reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# 학습에 실제 사용된 열 순서로 재정렬(누락은 0으로 채우고, 여분은 버림)\n",
    "feature_names_fit = X_all.columns.tolist()\n",
    "for c in feature_names_fit:\n",
    "    if c not in X_next_parts.columns:\n",
    "        X_next_parts[c] = 0.0\n",
    "X_next = X_next_parts[feature_names_fit].astype(float)\n",
    "\n",
    "# 예측 (Top-3)\n",
    "proba_next = xgb_final.predict_proba(X_next)\n",
    "pred_next  = xgb_final.predict(X_next)\n",
    "\n",
    "df_next_cls = grid_next[[\"ts_slot\",\"weekday\",\"slot_hour\",\"label_lag7\"]].copy()\n",
    "df_next_cls[\"pred_label\"] = le.inverse_transform(pred_next)\n",
    "\n",
    "order = np.argsort(proba_next, axis=1)[:, ::-1]\n",
    "labels_str = le.classes_\n",
    "k = min(3, proba_next.shape[1])\n",
    "df_next_cls[\"top1\"] = labels_str[order[:,0]]\n",
    "df_next_cls[\"p1\"]   = proba_next[np.arange(len(proba_next)), order[:,0]].astype(float)\n",
    "if k >= 2:\n",
    "    df_next_cls[\"top2\"] = labels_str[order[:,1]]\n",
    "    df_next_cls[\"p2\"]   = proba_next[np.arange(len(proba_next)), order[:,1]].astype(float)\n",
    "if k >= 3:\n",
    "    df_next_cls[\"top3\"] = labels_str[order[:,2]]\n",
    "    df_next_cls[\"p3\"]   = proba_next[np.arange(len(proba_next)), order[:,2]].astype(float)\n",
    "\n",
    "weekday_map = {0:\"월\",1:\"화\",2:\"수\",3:\"목\",4:\"금\",5:\"토\",6:\"일\"}\n",
    "df_next_cls[\"weekday_ko\"] = df_next_cls[\"weekday\"].map(weekday_map)\n",
    "\n",
    "df_next_cls.to_csv(\"cls_pred_tomorrow_xgb.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\">> 내일 분류 예측 저장: cls_pred_tomorrow_xgb.csv  (XGB, n_estimators=%d)\" % best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff930a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
